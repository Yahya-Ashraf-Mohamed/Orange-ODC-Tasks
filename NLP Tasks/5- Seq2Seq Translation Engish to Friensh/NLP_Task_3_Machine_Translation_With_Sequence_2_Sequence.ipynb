{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:17:45.815830Z","iopub.status.busy":"2024-09-20T06:17:45.815551Z","iopub.status.idle":"2024-09-20T06:17:45.820555Z","shell.execute_reply":"2024-09-20T06:17:45.819625Z","shell.execute_reply.started":"2024-09-20T06:17:45.815798Z"},"trusted":true},"outputs":[],"source":["# !python -m spacy download fr_core_news_sm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:17:45.822144Z","iopub.status.busy":"2024-09-20T06:17:45.821869Z","iopub.status.idle":"2024-09-20T06:17:45.833493Z","shell.execute_reply":"2024-09-20T06:17:45.832727Z","shell.execute_reply.started":"2024-09-20T06:17:45.822114Z"},"trusted":true},"outputs":[],"source":["# !pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-20T06:17:45.840010Z","iopub.status.busy":"2024-09-20T06:17:45.839709Z","iopub.status.idle":"2024-09-20T06:21:36.541605Z","shell.execute_reply":"2024-09-20T06:21:36.540537Z","shell.execute_reply.started":"2024-09-20T06:17:45.839973Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d87739e2ada4e14b27838e25a750973","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"41c6658bb15646cc892bea9b6e997937","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebc67608a0a44198ad631a6463f872dc","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ba094685b174ff1bc9d7150b69ea978","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a75813fda244ce0aab1482a4533c99b","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"079079cfe47947369b26be8832031cb7","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ea908c39def404e996566a0eddf96ec","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0fd221580d74c41ba96831b1f35c14c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import torch\n","from torch import nn\n","import spacy\n","from collections import Counter\n","from transformers import AutoTokenizer\n","\n","from transformers import BertTokenizer\n","from collections import Counter\n","\n","\n","# Load dataset from Kaggle\n","data = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv')\n","data = data[0:150]\n","\n","# Tokenization\n","# nlp_en = spacy.load(\"en_core_web_sm\")\n","# nlp_fr = spacy.load(\"fr_core_news_sm\")\n","\n","\n","# Load tokenizers\n","en_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","fr_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","\n","# Tokenize texts\n","def tokenize(text, lang):\n","    tokenizer = en_tokenizer if lang == 'en' else fr_tokenizer\n","    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text.lower()))\n","\n","# Apply tokenization\n","en_texts = data['en'].apply(lambda x: tokenize(str(x), 'en')).tolist()\n","fr_texts = data['fr'].apply(lambda x: tokenize(str(x), 'fr')).tolist()\n","\n","# Build vocabulary\n","def build_vocab(texts):\n","    vocab = Counter([token for text in texts for token in text])\n","    vocab = {word: i+2 for i, (word, _) in enumerate(vocab.most_common())}\n","    vocab['<pad>'] = 0\n","    vocab['<unk>'] = 1\n","    return vocab\n","\n","en_vocab = build_vocab(en_texts)\n","fr_vocab = build_vocab(fr_texts)\n","\n","INPUT_DIM = len(en_vocab)\n","OUTPUT_DIM = len(fr_vocab)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:21:36.544025Z","iopub.status.busy":"2024-09-20T06:21:36.543701Z","iopub.status.idle":"2024-09-20T06:21:36.562260Z","shell.execute_reply":"2024-09-20T06:21:36.561306Z","shell.execute_reply.started":"2024-09-20T06:21:36.543991Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n","\n","class Attention(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(Attention, self).__init__()\n","        self.attention = nn.Linear(hidden_dim * 2, hidden_dim)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        src_len = encoder_outputs.shape[1]\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        energy = torch.tanh(self.attention(torch.cat((hidden, encoder_outputs), dim=2)))\n","        attention = torch.sum(energy, dim=2)\n","        return nn.functional.softmax(attention, dim=1)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout):\n","        super(Decoder, self).__init__()\n","        self.output_dim = output_dim\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.attention = Attention(hidden_dim)\n","\n","    def forward(self, input, hidden, cell, encoder_outputs):\n","        input = input.unsqueeze(1)\n","        embedded = self.dropout(self.embedding(input))\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        attention = self.attention(hidden, encoder_outputs)\n","        encoder_outputs = encoder_outputs.permute(0, 2, 1)\n","        context = torch.bmm(attention.unsqueeze(1), encoder_outputs).permute(0, 2, 1)\n","        output = self.fc_out(output.squeeze(1) + context.squeeze(1))\n","        return output, hidden, cell\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:21:36.563883Z","iopub.status.busy":"2024-09-20T06:21:36.563581Z","iopub.status.idle":"2024-09-20T06:21:36.577295Z","shell.execute_reply":"2024-09-20T06:21:36.576529Z","shell.execute_reply.started":"2024-09-20T06:21:36.563851Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        batch_size = src.shape[0]\n","        trg_len = trg.shape[1]\n","        output_dim = self.decoder.output_dim\n","        \n","        outputs = torch.zeros(batch_size, trg_len, output_dim).to(src.device)\n","        \n","        hidden, cell = self.encoder(src)\n","        input = trg[:, 0]  # Start with the <sos> token\n","\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n","            outputs[:, t] = output\n","            \n","            teacher_force = torch.rand(1) < teacher_forcing_ratio\n","            \n","            input = trg[:, t] if teacher_force else output.argmax(1)\n","\n","        return outputs\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:42:05.470140Z","iopub.status.busy":"2024-09-20T06:42:05.469277Z","iopub.status.idle":"2024-09-20T06:42:05.479039Z","shell.execute_reply":"2024-09-20T06:42:05.477979Z","shell.execute_reply.started":"2024-09-20T06:42:05.470092Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","class TranslationDataset(Dataset):\n","    def __init__(self, src_texts, trg_texts):\n","        self.src_texts = src_texts\n","        self.trg_texts = trg_texts\n","\n","    def __len__(self):\n","        return len(self.src_texts)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'src': torch.tensor(self.src_texts[idx], dtype=torch.long),\n","            'trg': torch.tensor(self.trg_texts[idx], dtype=torch.long)\n","        }\n","\n","def collate_fn(batch):\n","    src_batch = [item['src'] for item in batch]\n","    trg_batch = [item['trg'] for item in batch]\n","\n","    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n","    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n","\n","    return {'src': src_padded, 'trg': trg_padded}\n","\n","\n","# Create dataset\n","dataset = TranslationDataset(en_texts, fr_texts)\n","\n","# Create data loader\n","train_iterator = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:42:06.504368Z","iopub.status.busy":"2024-09-20T06:42:06.503519Z","iopub.status.idle":"2024-09-20T06:42:06.511104Z","shell.execute_reply":"2024-09-20T06:42:06.510123Z","shell.execute_reply.started":"2024-09-20T06:42:06.504322Z"},"trusted":true},"outputs":[],"source":["def train(model, iterator, optimizer, criterion):\n","    model.train()\n","    epoch_loss = 0\n","    \n","    for batch in iterator:\n","        src = batch['src'].to(device)\n","        trg = batch['trg'].to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(src, trg)\n","        \n","        output_dim = output.shape[-1]\n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        loss = criterion(output, trg)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-20T06:42:30.694415Z","iopub.status.busy":"2024-09-20T06:42:30.694026Z","iopub.status.idle":"2024-09-20T06:42:32.104256Z","shell.execute_reply":"2024-09-20T06:42:32.102764Z","shell.execute_reply.started":"2024-09-20T06:42:30.694372Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [6,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [154,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [96,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [97,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [98,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [99,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [100,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [101,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [102,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [103,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [104,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [105,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [106,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [107,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [108,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [109,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [110,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [111,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [112,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [113,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [114,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [115,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [116,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [117,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [118,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [119,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [120,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [121,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [122,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [123,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [124,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [125,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [126,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [43,0,0], thread: [127,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n","/usr/local/src/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1284: indexSelectLargeIndex: block: [2,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"]},{"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m---> 30\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m trg \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     10\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39moutput_dim\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(batch_size, trg_len, output_dim)\u001b[38;5;241m.\u001b[39mto(src\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 14\u001b[0m hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m trg[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Start with the <sos> token\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, trg_len):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src):\n\u001b[0;32m----> 9\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     outputs, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(embedded)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden, cell\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1295\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["import random\n","from torch.nn.utils.rnn import pad_sequence\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","INPUT_DIM = len(en_vocab)\n","OUTPUT_DIM = len(fr_vocab)\n","\n","# Define the rest of the model parameters\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 512\n","DEC_HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","# Initialize encoder and decoder\n","encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n","decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT).to(device)\n","model = Seq2Seq(encoder, decoder).to(device)\n","\n","# Initialize optimizer and loss function\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(ignore_index=fr_vocab['<pad>'])\n","\n","# Train the model for a few epochs\n","N_EPOCHS = 10\n","for epoch in range(N_EPOCHS):\n","    train_loss = train(model, train_iterator, optimizer, criterion)\n","    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.3f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-20T06:21:37.133480Z","iopub.status.idle":"2024-09-20T06:21:37.133809Z","shell.execute_reply":"2024-09-20T06:21:37.133660Z","shell.execute_reply.started":"2024-09-20T06:21:37.133643Z"},"trusted":true},"outputs":[],"source":["def translate_sentence(sentence, model, src_field, trg_field, device):\n","    model.eval()\n","    \n","    tokens = [token.lower() for token in tokenize_en(sentence)]\n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","    \n","    src_indexes = [src_field.vocab.stoi[t] for t in tokens]\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(src_tensor)\n","\n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","    for _ in range(100):  # Limit translation length\n","        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","        output, hidden, cell = model.decoder(trg_tensor, hidden, cell, encoder_outputs)\n","        \n","        pred_token = output.argmax(1).item()\n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","\n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","    return ' '.join(trg_tokens[1:-1])  # Exclude <sos> and <eos>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-20T06:21:37.134995Z","iopub.status.idle":"2024-09-20T06:21:37.135336Z","shell.execute_reply":"2024-09-20T06:21:37.135186Z","shell.execute_reply.started":"2024-09-20T06:21:37.135169Z"},"trusted":true},"outputs":[],"source":["example_sentence = \"This is a test sentence.\"\n","translated_sentence = translate_sentence(example_sentence, model, EN_TEXT, FR_TEXT, device)\n","print(translated_sentence)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1148896,"sourceId":1926230,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
